"""
Gradio ç»Ÿä¸€ç®¡ç†ç•Œé¢
åŒ…å«ï¼šæ•°æ®è·å–ã€æ¨ç†ç›‘æ§ã€å¾®è°ƒè®­ç»ƒã€æ¨¡å‹å¯¹æ¯”
"""
import gradio as gr
from pathlib import Path
from typing import List, Dict, Optional
import json
import pandas as pd

from configs.settings import settings
from src.adapters.chatts_training import ChatTSTrainingAdapter
from src.adapters.data_processing import DataProcessingAdapter
from src.adapters.check_outlier import CheckOutlierAdapter


# åˆå§‹åŒ–é€‚é…å™¨
training_adapter = ChatTSTrainingAdapter()
data_adapter = DataProcessingAdapter()
inference_adapter = CheckOutlierAdapter()

# ä¸ºäº†å…¼å®¹æ€§ä¿ç•™æ—§å˜é‡å
adapter = training_adapter


def get_training_configs() -> List[str]:
    """è·å–è®­ç»ƒé…ç½®åˆ—è¡¨"""
    configs = adapter.list_configs()
    return [c["name"] for c in configs]


def get_trained_models() -> List[str]:
    """è·å–å·²è®­ç»ƒæ¨¡å‹åˆ—è¡¨"""
    models = adapter.list_models()
    return [m["name"] for m in models]


def get_model_info(model_name: str) -> str:
    """è·å–æ¨¡å‹è¯¦ç»†ä¿¡æ¯"""
    if not model_name:
        return "è¯·é€‰æ‹©ä¸€ä¸ªæ¨¡å‹"
    
    models = adapter.list_models()
    model = next((m for m in models if m["name"] == model_name), None)
    
    if not model:
        return "æ¨¡å‹ä¸å­˜åœ¨"
    
    info_lines = [
        f"**æ¨¡å‹åç§°**: {model['name']}",
        f"**ç±»å‹**: {model.get('type', 'unknown')}",
        f"**æ£€æŸ¥ç‚¹**: {', '.join(model.get('checkpoints', []))}",
        f"**è®­ç»ƒæ­¥æ•°**: {model.get('global_step', 'N/A')}",
    ]
    
    # è®­ç»ƒç»“æœ
    train_results = model.get("train_results", {})
    if train_results:
        info_lines.append(f"**è®­ç»ƒ Loss**: {train_results.get('train_loss', 'N/A'):.4f}")
        info_lines.append(f"**è®­ç»ƒæ—¶é•¿**: {train_results.get('train_runtime', 'N/A'):.1f}s")
    
    return "\n\n".join(info_lines)


def get_loss_plot(model_name: str):
    """è·å– Loss æ›²çº¿å›¾"""
    if not model_name:
        return None
    
    models = adapter.list_models()
    model = next((m for m in models if m["name"] == model_name), None)
    
    if not model or not model.get("loss_image"):
        return None
    
    loss_image = model.get("loss_image")
    if Path(loss_image).exists():
        return loss_image
    return None


def get_comparison_plot(model_names: List[str]):
    """è·å–å¤šä¸ªæ¨¡å‹çš„ Loss å¯¹æ¯”å›¾ (ä½¿ç”¨ Matplotlib åŠ¨æ€ç”Ÿæˆ)"""
    if not model_names or len(model_names) == 0:
        return None
    
    import matplotlib.pyplot as plt
    import pandas as pd
    
    plt.figure(figsize=(10, 6))
    
    for name in model_names:
        models = adapter.list_models()
        model = next((m for m in models if m["name"] == name), None)
        if not model:
            continue
            
        logs = adapter.get_training_log(model["path"])
        if not logs:
            continue
            
        df = pd.DataFrame([{"step": l.get("current_steps", 0), "loss": l.get("loss")} for l in logs if "loss" in l])
        if not df.empty:
            plt.plot(df["step"], df["loss"], label=name)
            
    plt.xlabel("Steps")
    plt.ylabel("Loss")
    plt.title("Model Comparison: Training Loss")
    plt.legend()
    plt.grid(True)
    
    # ä¿å­˜åˆ°é¡¹ç›®æœ¬åœ°ä¸´æ—¶ç›®å½•ï¼Œé¿å…ç³»ç»Ÿ /tmp æƒé™é—®é¢˜
    import uuid
    
    temp_dir = Path("temp_images")
    temp_dir.mkdir(exist_ok=True)
    
    output_path = temp_dir / f"compare_{uuid.uuid4().hex[:8]}.png"
    plt.savefig(str(output_path))
    plt.close()
    
    return str(output_path)


# ==================== æ•°æ®è·å–è¾…åŠ©å‡½æ•° ====================

def get_datasets_table() -> pd.DataFrame:
    """è·å–æ•°æ®é›†åˆ—è¡¨å¹¶è¿”å› DataFrame"""
    datasets = data_adapter.list_datasets()
    if not datasets:
        return pd.DataFrame(columns=["æ–‡ä»¶å", "å¤§å° (KB)", "ä¿®æ”¹æ—¶é—´"])
    
    from datetime import datetime
    rows = []
    for d in datasets:
        rows.append({
            "æ–‡ä»¶å": d["filename"],
            "å¤§å° (KB)": round(d["size_bytes"] / 1024, 2),
            "ä¿®æ”¹æ—¶é—´": datetime.fromtimestamp(d["modified_time"]).strftime("%Y-%m-%d %H:%M")
        })
    return pd.DataFrame(rows)


def get_dataset_names() -> List[str]:
    """è·å–æ•°æ®é›†æ–‡ä»¶ååˆ—è¡¨"""
    datasets = data_adapter.list_datasets()
    return [d["filename"] for d in datasets]


def preview_dataset(filename: str) -> tuple:
    """é¢„è§ˆæ•°æ®é›†ï¼Œè¿”å› (è¡¨æ ¼æ•°æ®, æ›²çº¿å›¾)"""
    if not filename:
        return pd.DataFrame(), None
    
    try:
        # è·å–é¢„è§ˆæ•°æ®
        data = data_adapter.preview_csv(filename, limit=200)
        df = pd.DataFrame(data)
        
        # ç”Ÿæˆæ›²çº¿å›¾
        import matplotlib.pyplot as plt
        plt.figure(figsize=(12, 4))
        
        # å‡è®¾ç¬¬ä¸€åˆ—æ˜¯æ—¶é—´æˆ–ç´¢å¼•ï¼Œåé¢çš„åˆ—æ˜¯æ•°å€¼
        numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
        if numeric_cols:
            for col in numeric_cols[:3]:  # æœ€å¤šæ˜¾ç¤º 3 æ¡æ›²çº¿
                plt.plot(df.index, df[col], label=col, alpha=0.8)
            plt.xlabel("ç´¢å¼•")
            plt.ylabel("å€¼")
            plt.title(f"æ•°æ®é¢„è§ˆ: {filename}")
            plt.legend()
            plt.grid(True, alpha=0.3)
        
        temp_dir = Path("temp_images")
        temp_dir.mkdir(exist_ok=True)
        import uuid
        plot_path = temp_dir / f"preview_{uuid.uuid4().hex[:8]}.png"
        plt.savefig(str(plot_path), dpi=100, bbox_inches='tight')
        plt.close()
        
        return df, str(plot_path)
    except Exception as e:
        return pd.DataFrame({"é”™è¯¯": [str(e)]}), None


def start_acquire_task(source: str, target_points: int) -> str:
    """å¯åŠ¨æ•°æ®é‡‡é›†ä»»åŠ¡"""
    if not source:
        return "âŒ è¯·è¾“å…¥ IoTDB æºè·¯å¾„"
    
    try:
        result = data_adapter.run_acquire_task(
            task_id="manual",
            source=source,
            target_points=int(target_points)
        )
        if result.get("success"):
            return f"âœ… é‡‡é›†ä»»åŠ¡å®Œæˆ\n\n{result.get('stdout', '')[:500]}"
        else:
            return f"âŒ é‡‡é›†å¤±è´¥: {result.get('error', result.get('stderr', 'æœªçŸ¥é”™è¯¯'))}"
    except Exception as e:
        return f"âŒ å¯åŠ¨å¤±è´¥: {str(e)}"


# ==================== æ¨ç†ç›‘æ§è¾…åŠ©å‡½æ•° ====================

def get_algorithms() -> List[str]:
    """è·å–å¯ç”¨ç®—æ³•åˆ—è¡¨"""
    return ["chatts", "adtk_hbos", "ensemble"]


def get_inference_models() -> List[str]:
    """è·å–å¯ç”¨äºæ¨ç†çš„æ¨¡å‹åˆ—è¡¨"""
    models = training_adapter.list_models()
    return [m["name"] for m in models]


def start_inference_task(algorithm: str, model: str, files: List[str]) -> str:
    """å¯åŠ¨æ¨ç†ä»»åŠ¡"""
    if not algorithm:
        return "âŒ è¯·é€‰æ‹©ç®—æ³•"
    if not files:
        return "âŒ è¯·é€‰æ‹©è¾“å…¥æ–‡ä»¶"
    
    # å°†é€‰ä¸­çš„æ–‡ä»¶åè½¬æ¢ä¸ºå®Œæ•´è·¯å¾„
    file_paths = []
    for f in files:
        full_path = data_adapter.data_path / f
        if full_path.exists():
            file_paths.append(str(full_path))
    
    if not file_paths:
        return "âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„è¾“å…¥æ–‡ä»¶"
    
    import uuid
    task_id = str(uuid.uuid4())[:8]
    
    try:
        # è¿™é‡Œåº”è¯¥è°ƒç”¨å¼‚æ­¥ä»»åŠ¡ï¼Œç›®å‰è¿”å›æç¤º
        return f"""âœ… æ¨ç†ä»»åŠ¡å·²æäº¤

**ä»»åŠ¡ ID**: {task_id}
**ç®—æ³•**: {algorithm}
**æ¨¡å‹**: {model or 'é»˜è®¤æ¨¡å‹'}
**æ–‡ä»¶æ•°**: {len(file_paths)}

è¯·é€šè¿‡ API `/api/v1/inference/status/{task_id}` æŸ¥è¯¢è¿›åº¦ã€‚
"""
    except Exception as e:
        return f"âŒ å¯åŠ¨å¤±è´¥: {str(e)}"


def get_task_status_table() -> pd.DataFrame:
    """è·å–ä»»åŠ¡çŠ¶æ€åˆ—è¡¨ (ä»æ•°æ®åº“è¯»å–)"""
    try:
        from src.db.database import SessionLocal, Task
        db = SessionLocal()
        tasks = db.query(Task).order_by(Task.created_at.desc()).limit(20).all()
        db.close()
        
        if not tasks:
            return pd.DataFrame(columns=["ID", "ç±»å‹", "çŠ¶æ€", "åˆ›å»ºæ—¶é—´"])
        
        rows = []
        for t in tasks:
            rows.append({
                "ID": t.id[:8] + "...",
                "ç±»å‹": t.type,
                "çŠ¶æ€": t.status,
                "åˆ›å»ºæ—¶é—´": t.created_at.strftime("%H:%M:%S") if t.created_at else "N/A"
            })
        return pd.DataFrame(rows)
    except Exception as e:
        return pd.DataFrame({"é”™è¯¯": [str(e)]})


def start_training(
    config_name: str,
    learning_rate: str,
    num_epochs: float,
    batch_size: int,
    lora_rank: int,
    lora_alpha: int,
    output_name: str
) -> str:
    """å¯åŠ¨è®­ç»ƒ"""
    if not config_name:
        return "âŒ è¯·é€‰æ‹©è®­ç»ƒé…ç½®"
    
    if not output_name:
        return "âŒ è¯·è¾“å…¥è¾“å‡ºç›®å½•åç§°"
    
    # è°ƒç”¨é€‚é…å™¨å¯åŠ¨è®­ç»ƒ
    import uuid
    task_id = str(uuid.uuid4())[:8]
    
    try:
        # è¿™é‡Œåº”è¯¥è°ƒç”¨ adapter.run_trainingï¼Œä½†ç”±äºæ˜¯åå°ä»»åŠ¡ï¼Œå…ˆè¿”å›æç¤º
        return f"""âœ… è®­ç»ƒä»»åŠ¡å·²æäº¤

**ä»»åŠ¡ ID**: {task_id}
**é…ç½®**: {config_name}
**è¾“å‡ºç›®å½•**: {output_name}

**å‚æ•°**:
- å­¦ä¹ ç‡: {learning_rate}
- è®­ç»ƒè½®æ•°: {num_epochs}
- æ‰¹æ¬¡å¤§å°: {batch_size}
- LoRA Rank: {lora_rank}
- LoRA Alpha: {lora_alpha}

è¯·é€šè¿‡ API `/api/v1/training/status/{task_id}` æŸ¥è¯¢è¿›åº¦ã€‚
"""
    except Exception as e:
        return f"âŒ å¯åŠ¨å¤±è´¥: {str(e)}"


def create_training_ui() -> gr.Blocks:
    """åˆ›å»ºç»Ÿä¸€ç®¡ç†ç•Œé¢ï¼ˆæ•°æ®è·å–ã€æ¨ç†ç›‘æ§ã€å¾®è°ƒè®­ç»ƒï¼‰"""
    
    with gr.Blocks(title="TS-Iteration-Loop", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸ”„ TS-Iteration-Loop æ—¶åºè¿­ä»£å¹³å°")
        gr.Markdown("æ•´åˆæ•°æ®è·å–ã€æ¨ç†ç›‘æ§ã€å¾®è°ƒè®­ç»ƒçš„ç»Ÿä¸€ç®¡ç†ç•Œé¢")
        
        # ==================== æ•°æ®è·å– Tab ====================
        with gr.Tab("ğŸ“ æ•°æ®è·å–"):
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("### æ•°æ®é›†åˆ—è¡¨")
                    datasets_table = gr.Dataframe(
                        value=get_datasets_table(),
                        label="å·²æœ‰æ•°æ®é›†",
                        interactive=False
                    )
                    refresh_datasets_btn = gr.Button("ğŸ”„ åˆ·æ–°åˆ—è¡¨")
                    
                    gr.Markdown("### é¢„è§ˆæ•°æ®")
                    preview_dropdown = gr.Dropdown(
                        label="é€‰æ‹©æ•°æ®é›†",
                        choices=get_dataset_names(),
                        interactive=True
                    )
                
                with gr.Column(scale=2):
                    gr.Markdown("### æ•°æ®é‡‡é›†é…ç½®")
                    with gr.Row():
                        source_input = gr.Textbox(
                            label="IoTDB æºè·¯å¾„",
                            placeholder="root.xxx.yyy.zzz",
                            scale=2
                        )
                        target_points = gr.Slider(
                            label="ç›®æ ‡ç‚¹æ•°",
                            minimum=1000,
                            maximum=10000,
                            value=5000,
                            step=500,
                            scale=1
                        )
                    acquire_btn = gr.Button("ğŸ“¥ å¼€å§‹é‡‡é›†", variant="primary")
                    acquire_output = gr.Markdown(value="ç­‰å¾…é‡‡é›†...")
            
            # æ•°æ®é¢„è§ˆåŒºåŸŸ
            with gr.Row():
                with gr.Column(scale=1):
                    preview_table = gr.Dataframe(
                        label="æ•°æ®é¢„è§ˆ (å‰200è¡Œ)",
                        interactive=False
                    )
                with gr.Column(scale=1):
                    preview_plot = gr.Image(label="æ›²çº¿é¢„è§ˆ")
            
            # äº‹ä»¶ç»‘å®š - æ•°æ®è·å–
            refresh_datasets_btn.click(
                fn=get_datasets_table,
                outputs=datasets_table
            )
            refresh_datasets_btn.click(
                fn=lambda: gr.Dropdown(choices=get_dataset_names()),
                outputs=preview_dropdown
            )
            preview_dropdown.change(
                fn=preview_dataset,
                inputs=preview_dropdown,
                outputs=[preview_table, preview_plot]
            )
            acquire_btn.click(
                fn=start_acquire_task,
                inputs=[source_input, target_points],
                outputs=acquire_output
            )
        
        # ==================== æ¨ç†ç›‘æ§ Tab ====================
        with gr.Tab("ğŸ” æ¨ç†ç›‘æ§"):
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("### æ–°å»ºæ¨ç†ä»»åŠ¡")
                    algo_dropdown = gr.Dropdown(
                        label="é€‰æ‹©ç®—æ³•",
                        choices=get_algorithms(),
                        value="chatts",
                        interactive=True
                    )
                    model_select = gr.Dropdown(
                        label="é€‰æ‹©æ¨¡å‹ (å¯é€‰)",
                        choices=get_inference_models(),
                        interactive=True
                    )
                    files_select = gr.CheckboxGroup(
                        label="é€‰æ‹©è¾“å…¥æ–‡ä»¶",
                        choices=get_dataset_names()
                    )
                    submit_inference_btn = gr.Button("ğŸš€ æäº¤ä»»åŠ¡", variant="primary")
                    inference_output = gr.Markdown(value="ç­‰å¾…æäº¤...")
                
                with gr.Column(scale=2):
                    gr.Markdown("### ä»»åŠ¡çŠ¶æ€")
                    task_table = gr.Dataframe(
                        value=get_task_status_table(),
                        label="æœ€è¿‘ 20 æ¡ä»»åŠ¡",
                        interactive=False
                    )
                    with gr.Row():
                        refresh_tasks_btn = gr.Button("ğŸ”„ åˆ·æ–°çŠ¶æ€")
                        # auto_refresh = gr.Checkbox(label="è‡ªåŠ¨åˆ·æ–° (5s)", value=False)
            
            # äº‹ä»¶ç»‘å®š - æ¨ç†ç›‘æ§
            submit_inference_btn.click(
                fn=start_inference_task,
                inputs=[algo_dropdown, model_select, files_select],
                outputs=inference_output
            )
            refresh_tasks_btn.click(
                fn=get_task_status_table,
                outputs=task_table
            )
            refresh_tasks_btn.click(
                fn=lambda: gr.CheckboxGroup(choices=get_dataset_names()),
                outputs=files_select
            )
            refresh_tasks_btn.click(
                fn=lambda: gr.Dropdown(choices=get_inference_models()),
                outputs=model_select
            )
        
        # ==================== æ ‡æ³¨å·¥å…· Tab ====================
        with gr.Tab("ğŸ·ï¸ æ ‡æ³¨å·¥å…·"):
            gr.Markdown("### æ—¶åºæ•°æ®æ ‡æ³¨")
            gr.Markdown(f"""
> [!NOTE]
> æ ‡æ³¨å·¥å…·è¿è¡Œåœ¨ç‹¬ç«‹æœåŠ¡ä¸Šï¼Œç‚¹å‡»ä¸‹æ–¹é“¾æ¥è·³è½¬ã€‚

**æ ‡æ³¨å·¥å…·åœ°å€**: [http://localhost:5000](http://localhost:5000)

---

### ä½¿ç”¨è¯´æ˜

1. **æ‰“å¼€æ ‡æ³¨å·¥å…·**: ç‚¹å‡»ä¸Šæ–¹é“¾æ¥è¿›å…¥æ ‡æ³¨ç•Œé¢
2. **é€‰æ‹©æ•°æ®æ–‡ä»¶**: åœ¨æ ‡æ³¨å·¥å…·ä¸­é€‰æ‹©è¦æ ‡æ³¨çš„ CSV æ–‡ä»¶
3. **è¿›è¡Œæ ‡æ³¨**: ä½¿ç”¨æ¡†é€‰å·¥å…·æ ‡è®°å¼‚å¸¸åŒºé—´
4. **ä¿å­˜æ ‡æ³¨**: å®Œæˆåä¿å­˜æ ‡æ³¨ç»“æœ

### æ ‡æ³¨ä¸è¿­ä»£æµç¨‹

```
ğŸ“ æ•°æ®è·å– â†’ ğŸ·ï¸ äººå·¥æ ‡æ³¨ â†’ ğŸ¯ å¾®è°ƒè®­ç»ƒ â†’ ğŸ” æ¨ç†æ£€æµ‹ â†’ ğŸ·ï¸ å®¡æ ¸ä¿®æ­£ â†’ ğŸ¯ å†æ¬¡å¾®è°ƒ â†’ ...
```

### å¿«é€Ÿæ“ä½œ
""")
            with gr.Row():
                open_annotator_btn = gr.Button("ğŸ”— æ‰“å¼€æ ‡æ³¨å·¥å…· (æ–°æ ‡ç­¾é¡µ)", variant="primary", size="lg")
                gr.Markdown("""
<script>
function openAnnotator() {
    window.open('http://localhost:5000', '_blank');
}
</script>
""", visible=False)
            
            gr.Markdown("### å½“å‰æ ‡æ³¨çŠ¶æ€")
            with gr.Row():
                with gr.Column():
                    gr.Markdown("**å¯æ ‡æ³¨æ–‡ä»¶æ•°é‡**")
                    annotatable_count = gr.Textbox(
                        value=f"{len(get_dataset_names())} ä¸ªæ–‡ä»¶",
                        interactive=False,
                        show_label=False
                    )
                with gr.Column():
                    gr.Markdown("**æ ‡æ³¨å·¥å…·çŠ¶æ€**")
                    annotator_status = gr.Textbox(
                        value="è¯·è®¿é—®æ ‡æ³¨å·¥å…·æŸ¥çœ‹",
                        interactive=False,
                        show_label=False
                    )
            
            # JavaScript è·³è½¬ (Gradio é™åˆ¶ï¼Œä½¿ç”¨ HTML)
            open_annotator_btn.click(
                fn=lambda: "âœ… è¯·åœ¨æ–°æ ‡ç­¾é¡µä¸­æŸ¥çœ‹æ ‡æ³¨å·¥å…· (http://localhost:5000)",
                outputs=annotator_status
            )
        
        # ==================== å¾®è°ƒè®­ç»ƒ Tab (åŸæœ‰) ====================
        with gr.Tab("ğŸ¯ å¼€å§‹è®­ç»ƒ"):
            with gr.Row():
                with gr.Column(scale=2):
                    # åŸºç¡€é…ç½®
                    gr.Markdown("### åŸºç¡€é…ç½®")
                    config_dropdown = gr.Dropdown(
                        label="è®­ç»ƒé…ç½®",
                        choices=get_training_configs(),
                        interactive=True
                    )
                    output_name = gr.Textbox(
                        label="è¾“å‡ºç›®å½•åç§°",
                        placeholder="ä¾‹å¦‚: my_model_v1"
                    )
                    
                    with gr.Row():
                        learning_rate = gr.Textbox(
                            label="å­¦ä¹ ç‡",
                            value="2e-5"
                        )
                        num_epochs = gr.Number(
                            label="è®­ç»ƒè½®æ•°",
                            value=3.0
                        )
                        batch_size = gr.Slider(
                            label="æ‰¹æ¬¡å¤§å°",
                            minimum=1,
                            maximum=32,
                            value=2,
                            step=1
                        )
                    
                    # LoRA é…ç½®ï¼ˆæŠ˜å ï¼‰
                    with gr.Accordion("LoRA é…ç½®", open=False):
                        with gr.Row():
                            lora_rank = gr.Slider(
                                label="LoRA Rank",
                                minimum=1,
                                maximum=128,
                                value=8,
                                step=1
                            )
                            lora_alpha = gr.Slider(
                                label="LoRA Alpha",
                                minimum=1,
                                maximum=256,
                                value=16,
                                step=1
                            )
                    
                    # æ§åˆ¶æŒ‰é’®
                    with gr.Row():
                        start_btn = gr.Button("ğŸš€ å¼€å§‹è®­ç»ƒ", variant="primary")
                        refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°é…ç½®")
                
                with gr.Column(scale=1):
                    # è¾“å‡ºåŒºåŸŸ
                    gr.Markdown("### è®­ç»ƒçŠ¶æ€")
                    output_box = gr.Markdown(value="ç­‰å¾…å¼€å§‹è®­ç»ƒ...")
            
            # äº‹ä»¶ç»‘å®š
            start_btn.click(
                fn=start_training,
                inputs=[
                    config_dropdown, learning_rate, num_epochs,
                    batch_size, lora_rank, lora_alpha, output_name
                ],
                outputs=output_box
            )
            refresh_btn.click(
                fn=lambda: gr.Dropdown(choices=get_training_configs()),
                outputs=config_dropdown
            )
        
        with gr.Tab("ğŸ“Š å·²è®­ç»ƒæ¨¡å‹"):
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("### æ¨¡å‹åˆ—è¡¨")
                    model_dropdown = gr.Dropdown(
                        label="é€‰æ‹©æ¨¡å‹",
                        choices=get_trained_models(),
                        interactive=True
                    )
                    refresh_models_btn = gr.Button("ğŸ”„ åˆ·æ–°åˆ—è¡¨")
                
                with gr.Column(scale=2):
                    gr.Markdown("### æ¨¡å‹è¯¦æƒ…")
                    model_info = gr.Markdown(value="è¯·é€‰æ‹©ä¸€ä¸ªæ¨¡å‹")
                    
                    gr.Markdown("### Loss æ›²çº¿")
                    loss_image = gr.Image(label="Training Loss", type="filepath")
            
            # äº‹ä»¶ç»‘å®š
            model_dropdown.change(
                fn=get_model_info,
                inputs=model_dropdown,
                outputs=model_info
            )
            model_dropdown.change(
                fn=get_loss_plot,
                inputs=model_dropdown,
                outputs=loss_image
            )
            refresh_models_btn.click(
                fn=lambda: gr.Dropdown(choices=get_trained_models()),
                outputs=model_dropdown
            )
            
        with gr.Tab("âš–ï¸ æ¨¡å‹å¯¹æ¯”"):
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("### é€‰æ‹©å¯¹æ¯”æ¨¡å‹")
                    compare_models = gr.CheckboxGroup(
                        label="æ¨¡å‹åˆ—è¡¨",
                        choices=get_trained_models()
                    )
                    compare_btn = gr.Button("ğŸ“Š ç”Ÿæˆå¯¹æ¯”å›¾", variant="primary")
                    refresh_compare_btn = gr.Button("ğŸ”„ åˆ·æ–°åˆ—è¡¨")
                
                with gr.Column(scale=3):
                    gr.Markdown("### å¯¹æ¯”ç»“æœ")
                    comparison_plot = gr.Image(label="Loss Comparison")
            
            # äº‹ä»¶ç»‘å®š
            compare_btn.click(
                fn=get_comparison_plot,
                inputs=compare_models,
                outputs=comparison_plot
            )
            refresh_compare_btn.click(
                fn=lambda: gr.CheckboxGroup(choices=get_trained_models()),
                outputs=compare_models
            )
        
        with gr.Tab("âš™ï¸ é…ç½®è¯´æ˜"):
            gr.Markdown("""
## è®­ç»ƒé…ç½®è¯´æ˜

### åŸºç¡€å‚æ•°

| å‚æ•° | è¯´æ˜ | æ¨èå€¼ |
|------|------|--------|
| **å­¦ä¹ ç‡** | æ¨¡å‹æ›´æ–°æ­¥é•¿ | 2e-5 ~ 5e-5 |
| **è®­ç»ƒè½®æ•°** | å®Œæ•´éå†æ•°æ®é›†æ¬¡æ•° | 3 ~ 5 |
| **æ‰¹æ¬¡å¤§å°** | æ¯æ¬¡æ›´æ–°çš„æ ·æœ¬æ•° | 2 ~ 8 (å–å†³äºæ˜¾å­˜) |

### LoRA å‚æ•°

| å‚æ•° | è¯´æ˜ | æ¨èå€¼ |
|------|------|--------|
| **LoRA Rank** | ä½ç§©åˆ†è§£ç»´åº¦ | 8 ~ 64 |
| **LoRA Alpha** | ç¼©æ”¾å› å­ | é€šå¸¸ä¸º Rank çš„ 2 å€ |

### æ˜¾å­˜éœ€æ±‚

| æ¨¡å‹ | æ‰¹æ¬¡å¤§å° | æ˜¾å­˜éœ€æ±‚ |
|------|---------|---------|
| ChatTS-8B + LoRA | 2 | ~16GB |
| ChatTS-8B + LoRA | 4 | ~24GB |
| ChatTS-14B + LoRA | 2 | ~24GB |

### è®­ç»ƒè„šæœ¬

å¯ç”¨çš„è®­ç»ƒé…ç½®æ¥è‡ª `/home/douff/ts/ChatTS-Training/scripts/lora/` ç›®å½•ã€‚
""")
    
    return demo


# åˆ›å»ºå…¨å±€ Gradio åº”ç”¨å®ä¾‹
training_ui = create_training_ui()
