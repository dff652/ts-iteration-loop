#!/usr/bin/env python3
"""
å°†æ ‡æ³¨JSONæ–‡ä»¶ä»å½“å‰æ ¼å¼è½¬æ¢ä¸ºå¯¹è¯æ ¼å¼
"""
import json
import os
import re
from pathlib import Path

# å®šä¹‰å¼‚å¸¸ç±»å‹æ˜ å°„
ANOMALY_TYPE_MAPPING = {
    "ä¸Šè¡Œå°–å³°": "ç«–ç›´å°–å³°",
    "ä¸‹è¡Œå°–å³°": "ç«–ç›´å°–å³°",
    "åŒå‘å°–å³°": "ç«–ç›´å°–å³°",
    "ç‚¹å¼‚å¸¸": "ç«–ç›´å°–å³°",
    "é˜¶è·ƒ": "é˜¶è·ƒçªå˜",
    "çªç„¶æ¼‚ç§»": "é˜¶è·ƒçªå˜",
    "ç¼“æ…¢æ¼‚ç§»": "æ¨¡å¼å˜åŒ–",
    "æ¨¡å¼çªå˜": "æ¨¡å¼å˜åŒ–",
    "å¼‚å¸¸å¹³å°": "å¼‚å¸¸å¹³å°"
}

def extract_point_name(annotation_filename):
    """ä»æ ‡æ³¨æ–‡ä»¶åä¸­æå–ç‚¹ä½åç§°
    ä¾‹å¦‚: annotations_æ•°æ®é›†zhlh_100_AC6403B.PV.json -> AC6403B.PV
    """
    # ç§»é™¤ "annotations_æ•°æ®é›†zhlh_100_" å‰ç¼€å’Œ ".json" åç¼€
    match = re.search(r'annotations_æ•°æ®é›†zhlh_100_(.+)\.json$', annotation_filename)
    if match:
        return match.group(1)
    return None

def find_image_file(point_name, image_dir):
    """æ ¹æ®ç‚¹ä½åç§°æŸ¥æ‰¾å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶"""
    # å›¾ç‰‡æ–‡ä»¶æ ¼å¼: zhlh_100_{point_name}.jpg
    image_filename = f"zhlh_100_{point_name}.jpg"
    image_path = os.path.join(image_dir, image_filename)
    
    if os.path.exists(image_path):
        return image_path
    return None

def map_anomaly_type(original_type):
    """å°†åŸå§‹å¼‚å¸¸ç±»å‹æ˜ å°„åˆ°ç›®æ ‡ç±»å‹"""
    return ANOMALY_TYPE_MAPPING.get(original_type, "æ¨¡å¼å˜åŒ–")

def generate_reason(label_text, interval):
    """æ ¹æ®æ ‡ç­¾ç±»å‹å’ŒåŒºé—´ç”ŸæˆåŸå› è¯´æ˜"""
    start, end = interval
    length = end - start + 1
    
    # æ ¹æ®å®é™…çš„æ ‡ç­¾ç±»å‹ç”Ÿæˆæ›´ç²¾ç¡®çš„æè¿°
    if label_text == "ä¸Šè¡Œå°–å³°":
        if start == end:
            return f"ç´¢å¼•ä½ç½®{start}å¤„æ•°æ®å‡ºç°å‘ä¸Šå°–å³°,æ•°å€¼æ€¥å‰§ä¸Šå‡åè¿…é€Ÿå›è½"
        else:
            return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®å‡ºç°å‘ä¸Šå°–å³°,æ•°å€¼æ€¥å‰§ä¸Šå‡åè¿…é€Ÿå›è½"
    
    elif label_text == "ä¸‹è¡Œå°–å³°":
        if start == end:
            return f"ç´¢å¼•ä½ç½®{start}å¤„æ•°æ®å‡ºç°å‘ä¸‹å°–å³°,æ•°å€¼æ€¥å‰§ä¸‹é™åè¿…é€Ÿå›å‡"
        else:
            return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®å‡ºç°å‘ä¸‹å°–å³°,æ•°å€¼æ€¥å‰§ä¸‹é™åè¿…é€Ÿå›å‡"
    
    elif label_text == "åŒå‘å°–å³°":
        if start == end:
            return f"ç´¢å¼•ä½ç½®{start}å¤„æ•°æ®å‡ºç°åŒå‘å°–å³°,æ•°å€¼å…ˆæ€¥å‰§å˜åŒ–ååå‘å˜åŒ–"
        else:
            return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®å‡ºç°åŒå‘å°–å³°,æ•°å€¼å‘ˆç°å‰§çƒˆéœ‡è¡"
    
    elif label_text == "é˜¶è·ƒä¸Šå‡":
        return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®å‘ç”Ÿé˜¶è·ƒä¸Šå‡,æ•°å€¼å¿«é€Ÿè·ƒè¿åˆ°æ›´é«˜æ°´å¹³"
    
    elif label_text == "é˜¶è·ƒä¸‹é™":
        return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®å‘ç”Ÿé˜¶è·ƒä¸‹é™,æ•°å€¼å¿«é€Ÿè·ƒè¿åˆ°æ›´ä½æ°´å¹³"
    
    elif label_text == "çªç„¶æ¼‚ç§»":
        return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®å‘ç”Ÿçªç„¶æ¼‚ç§»,åŸºçº¿æ°´å¹³å‘ç”Ÿçªå˜"
    
    elif label_text == "ç¼“æ…¢æ¼‚ç§»":
        return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®å‘ç”Ÿç¼“æ…¢æ¼‚ç§»,åŸºçº¿æ°´å¹³é€æ¸åç§»"
    
    elif label_text == "ç‚¹å¼‚å¸¸":
        if start == end:
            return f"ç´¢å¼•ä½ç½®{start}å¤„å­˜åœ¨å­¤ç«‹å¼‚å¸¸ç‚¹,ä¸å‘¨å›´æ•°æ®æ˜æ˜¾ä¸ç¬¦"
        else:
            return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…å­˜åœ¨å¤šä¸ªå­¤ç«‹å¼‚å¸¸ç‚¹"
    
    elif label_text == "åŒºé—´å¼‚å¸¸":
        return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®æ•´ä½“å¼‚å¸¸,ä¸æ­£å¸¸æ¨¡å¼å­˜åœ¨æ˜¾è‘—å·®å¼‚"
    
    elif label_text == "éœ‡è¡åŒºé—´":
        return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®å‘ˆç°å¼‚å¸¸éœ‡è¡,æ³¢åŠ¨å¹…åº¦æ˜æ˜¾å¢å¤§"
    
    elif label_text == "ä¸Šä¸‹æ–‡å¼‚å¸¸":
        return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®ä¸å‰åä¸Šä¸‹æ–‡ä¸ä¸€è‡´,å­˜åœ¨æ¨¡å¼çªå˜"
    
    # å…œåº•æè¿°ï¼ˆä¸åº”è¯¥åˆ°è¿™é‡Œï¼‰
    else:
        if start == end:
            return f"ç´¢å¼•ä½ç½®{start}å¤„æ•°æ®å­˜åœ¨å¼‚å¸¸"
        else:
            return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®å­˜åœ¨å¼‚å¸¸"

def convert_overall_attribute_to_chinese(overall_attr):
    """å°†overall_attributeè½¬æ¢ä¸ºä¸­æ–‡æè¿°"""
    # å®šä¹‰æ˜ å°„å…³ç³»
    mappings = {
        "frequency": {
            "high_freq": "é«˜é¢‘",
            "low_freq": "ä½é¢‘"
        },
        "noise": {
            "noisy": "é«˜å™ªå£°",
            "clean": "ä¸­ç­‰å™ªå£°",
            "almost_no_noise": "ä½å™ªå£°",
            "label_1766469170459": "æ— å™ªå£°"
        },
        "seasonal": {
            "has_periodic": "æœ‰å‘¨æœŸæ€§",
            "no_periodic": "æ— å‘¨æœŸæ€§",
            "label_1766475567943": "å±€éƒ¨æœ‰å‘¨æœŸæ€§"
        },
        "trend": {
            "increase": "ä¸Šå‡è¶‹åŠ¿",
            "decrease": "ä¸‹é™è¶‹åŠ¿",
            "stable": "è¶‹åŠ¿ç¨³å®š",
            "multiple": "å¤šæ®µå¼è¶‹åŠ¿",
            "label_1766469189296": "æ— æ˜æ˜¾è¶‹åŠ¿"
        }
    }
    
    descriptions = []
    for key, value in overall_attr.items():
        if value and key in mappings and value in mappings[key]:
            descriptions.append(mappings[key][value])
    
    return "ã€".join(descriptions) if descriptions else ""

def convert_annotation_to_conversation(annotation_data, image_path):
    """å°†æ ‡æ³¨æ•°æ®è½¬æ¢ä¸ºå¯¹è¯æ ¼å¼"""
    
    # ç”Ÿæˆç”¨æˆ·æç¤ºè¯ - ä½¿ç”¨å®é™…çš„æ ‡ç­¾ç±»å‹
    user_prompt = """<image>
ä½ æ˜¯ä¸€ä½æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹ä¸“å®¶ã€‚è¯·åˆ†æå›¾ä¸­çš„æ—¶é—´åºåˆ—æ•°æ®,è¯†åˆ«å¼‚å¸¸åŒºé—´ã€‚

å¼‚å¸¸ç±»å‹ï¼š
1. å°–å³°ç±»ï¼šä¸Šè¡Œå°–å³°ã€ä¸‹è¡Œå°–å³°ã€åŒå‘å°–å³°
2. é˜¶è·ƒç±»ï¼šé˜¶è·ƒä¸Šå‡ã€é˜¶è·ƒä¸‹é™
3. æ¼‚ç§»ç±»ï¼šçªç„¶æ¼‚ç§»ã€ç¼“æ…¢æ¼‚ç§»
4. ç‰¹æ®Šå¼‚å¸¸æ®µï¼šç‚¹å¼‚å¸¸ã€åŒºé—´å¼‚å¸¸ã€éœ‡è¡åŒºé—´ã€ä¸Šä¸‹æ–‡å¼‚å¸¸

è¯·åŸºäºå…¨å±€ä¿¡å·ç‰¹å¾è¯†åˆ«å¼‚å¸¸ã€‚è¾“å‡ºå¿…é¡»æ˜¯æ ‡å‡†JSONæ ¼å¼ï¼š

{"status":"success","detected_anomalies":[{"interval":[start,end],"type":"ç±»å‹","reason":"åŸå› "}]}

è‹¥æ— å¼‚å¸¸ï¼š
{"status":"success","detected_anomalies":[]}

è¯·ç²¾ç¡®æ ‡æ³¨å¼‚å¸¸åŒºé—´çš„èµ·æ­¢ç´¢å¼•ã€‚"""
    
    # ç”ŸæˆåŠ©æ‰‹å“åº”ï¼ˆåŒ…å«æ‰€æœ‰å¼‚å¸¸æ£€æµ‹ç»“æœå’Œoverall_attributeï¼‰
    detected_anomalies = []
    
    # å¤„ç†æ¯ä¸ªæ ‡æ³¨
    for annotation in annotation_data.get("annotations", []):
        label_text = annotation["label"]["text"]
        # ç›´æ¥ä½¿ç”¨åŸå§‹æ ‡ç­¾æ–‡æœ¬ä½œä¸ºtypeï¼Œä¸å†æ˜ å°„
        anomaly_type = label_text
        
        # å¤„ç†æ¯ä¸ªsegment
        for segment in annotation.get("segments", []):
            start = segment["start"]
            end = segment["end"]
            reason = generate_reason(label_text, [start, end])
            
            anomaly = {
                "interval": [start, end],
                "type": anomaly_type,
                "reason": reason
            }
            detected_anomalies.append(anomaly)
    
    # ç‰¹æ®Šå¤„ç†ï¼šæ— å¼‚å¸¸çš„æƒ…å†µï¼ˆæ²¡æœ‰annotationsæˆ–annotationsä¸ºç©ºï¼‰
    if not detected_anomalies:
        # æ— å¼‚å¸¸æ—¶ï¼Œè¾“å‡ºæ ¼å¼ï¼š{"status":"success","detected_anomalies":[{"type":"æ— å¼‚å¸¸","reason":"è¯¥æ•°æ®ä¸åšå¼‚å¸¸æ£€æµ‹"}]}
        no_anomaly_result = {
            "status": "success",
            "detected_anomalies": [
                {
                    "type": "æ— å¼‚å¸¸",
                    "reason": "è¯¥æ•°æ®ä¸åšå¼‚å¸¸æ£€æµ‹"
                }
            ]
        }
        assistant_value = json.dumps(no_anomaly_result, ensure_ascii=False)
        
        # å¦‚æœæœ‰overall_attributeï¼Œæ·»åŠ å…¨å±€å±æ€§
        if "overall_attribute" in annotation_data:
            overall_attr = annotation_data["overall_attribute"]
            filtered_attr = {k: v for k, v in overall_attr.items() if v}
            if filtered_attr:
                chinese_desc = convert_overall_attribute_to_chinese(filtered_attr)
                if chinese_desc:
                    overall_result = {
                        "status": "success",
                        "detected_anomalies": [
                            {
                                "type": "å…¨å±€å±æ€§",
                                "reason": chinese_desc
                            }
                        ]
                    }
                    assistant_value = assistant_value + "," + json.dumps(overall_result, ensure_ascii=False)
    else:
        # æœ‰å¼‚å¸¸çš„æƒ…å†µï¼šä¸ºæ¯ä¸ªå¼‚å¸¸åˆ›å»ºå•ç‹¬çš„JSONå¯¹è±¡ï¼Œç„¶åç”¨é€—å·è¿æ¥
        individual_results = []
        for anomaly in detected_anomalies:
            result = {
                "status": "success",
                "detected_anomalies": [anomaly]
            }
            individual_results.append(json.dumps(result, ensure_ascii=False))
        
        assistant_value = ",".join(individual_results)
        
        # æ·»åŠ overall_attributeåˆ°æœ€åï¼ˆè½¬æ¢ä¸ºä¸­æ–‡æ ¼å¼ï¼‰
        if "overall_attribute" in annotation_data:
            overall_attr = annotation_data["overall_attribute"]
            filtered_attr = {k: v for k, v in overall_attr.items() if v}
            if filtered_attr:
                chinese_desc = convert_overall_attribute_to_chinese(filtered_attr)
                if chinese_desc:
                    overall_result = {
                        "status": "success",
                        "detected_anomalies": [
                            {
                                "type": "å…¨å±€å±æ€§",
                                "reason": chinese_desc
                            }
                        ]
                    }
                    assistant_value = assistant_value + "," + json.dumps(overall_result, ensure_ascii=False)
    
    # æ„å»ºå¯¹è¯æ ¼å¼
    conversation = {
        "image": image_path,
        "conversations": [
            {
                "from": "user",
                "value": user_prompt
            },
            {
                "from": "assistant",
                "value": assistant_value
            }
        ]
    }
    
    return conversation

def convert_single_file(annotation_path, image_dir, output_dir=None):
    """è½¬æ¢å•ä¸ªæ ‡æ³¨æ–‡ä»¶"""
    
    # è¯»å–æ ‡æ³¨æ–‡ä»¶
    with open(annotation_path, 'r', encoding='utf-8') as f:
        annotation_data = json.load(f)
    
    # æå–ç‚¹ä½åç§°
    filename = os.path.basename(annotation_path)
    point_name = extract_point_name(filename)
    
    if not point_name:
        print(f"âš ï¸  æ— æ³•ä»æ–‡ä»¶åæå–ç‚¹ä½åç§°: {filename}")
        return None
    
    # æŸ¥æ‰¾å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶
    image_path = find_image_file(point_name, image_dir)
    
    if not image_path:
        print(f"âš ï¸  æ‰¾ä¸åˆ°å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶: {point_name}")
        return None
    
    # è½¬æ¢æ ¼å¼
    conversation = convert_annotation_to_conversation(annotation_data, image_path)
    
    # ä¿å­˜ç»“æœ
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        output_filename = f"converted_{point_name}.json"
        output_path = os.path.join(output_dir, output_filename)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(conversation, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… è½¬æ¢æˆåŠŸ: {filename} -> {output_filename}")
    
    return conversation

def batch_convert_all_files(annotation_dir, image_dir, output_file):
    """æ‰¹é‡è½¬æ¢æ‰€æœ‰æ ‡æ³¨æ–‡ä»¶å¹¶ä¿å­˜åˆ°ä¸€ä¸ªJSONæ–‡ä»¶ä¸­"""
    
    all_conversations = []
    success_count = 0
    failed_files = []
    
    # è·å–æ‰€æœ‰JSONæ–‡ä»¶
    json_files = [f for f in os.listdir(annotation_dir) if f.endswith('.json')]
    total_files = len(json_files)
    
    print(f"ğŸ”„ å¼€å§‹æ‰¹é‡è½¬æ¢ï¼Œå…± {total_files} ä¸ªæ–‡ä»¶...")
    print("=" * 80)
    
    for idx, filename in enumerate(json_files, 1):
        annotation_path = os.path.join(annotation_dir, filename)
        
        # æ˜¾ç¤ºè¿›åº¦
        print(f"[{idx}/{total_files}] å¤„ç†: {filename}", end=" ... ")
        
        try:
            # è¯»å–æ ‡æ³¨æ–‡ä»¶
            with open(annotation_path, 'r', encoding='utf-8') as f:
                annotation_data = json.load(f)
            
            # æå–ç‚¹ä½åç§°
            point_name = extract_point_name(filename)
            
            if not point_name:
                print("âŒ æ— æ³•æå–ç‚¹ä½åç§°")
                failed_files.append((filename, "æ— æ³•æå–ç‚¹ä½åç§°"))
                continue
            
            # æŸ¥æ‰¾å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶
            image_path = find_image_file(point_name, image_dir)
            
            if not image_path:
                print("âŒ æ‰¾ä¸åˆ°å¯¹åº”å›¾ç‰‡")
                failed_files.append((filename, "æ‰¾ä¸åˆ°å¯¹åº”å›¾ç‰‡"))
                continue
            
            # è½¬æ¢æ ¼å¼
            conversation = convert_annotation_to_conversation(annotation_data, image_path)
            all_conversations.append(conversation)
            
            success_count += 1
            print("âœ…")
            
        except Exception as e:
            print(f"âŒ é”™è¯¯: {str(e)}")
            failed_files.append((filename, str(e)))
    
    # ä¿å­˜æ‰€æœ‰è½¬æ¢ç»“æœåˆ°ä¸€ä¸ªJSONæ–‡ä»¶
    print("\n" + "=" * 80)
    print(f"ğŸ“Š è½¬æ¢ç»Ÿè®¡ï¼šæˆåŠŸ {success_count}/{total_files}")
    
    if failed_files:
        print(f"\nâš ï¸  å¤±è´¥çš„æ–‡ä»¶ ({len(failed_files)}):")
        for filename, reason in failed_files:
            print(f"  - {filename}: {reason}")
    
    # ä¿å­˜ç»“æœ
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_conversations, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ¨ æ‰€æœ‰è½¬æ¢ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print(f"ğŸ“¦ å…± {len(all_conversations)} æ¡å¯¹è¯æ•°æ®")
    
    return all_conversations

def main():
    """ä¸»å‡½æ•°"""
    # å®šä¹‰è·¯å¾„
    annotation_dir = "/home/douff/ts/timeseries-annotator-v2/backend/annotations/douff"
    image_dir = "/home/douff/æ•°æ®æ ‡æ³¨/data/picture_data"
    output_file = "/home/douff/converted_annotations/all_conversations.json"
    
    # æ‰¹é‡è½¬æ¢æ‰€æœ‰æ–‡ä»¶
    batch_convert_all_files(annotation_dir, image_dir, output_file)

if __name__ == "__main__":
    main()
