#!/usr/bin/env python3
"""
å°†æ ‡æ³¨JSONæ–‡ä»¶ä»å½“å‰æ ¼å¼è½¬æ¢ä¸ºå¯¹è¯æ ¼å¼
"""
import json
import os
import re
import tempfile
from datetime import datetime
from pathlib import Path
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates


# å®šä¹‰å¼‚å¸¸ç±»å‹æ˜ å°„
ANOMALY_TYPE_MAPPING = {
    "ä¸Šè¡Œå°–å³°": "ç«–ç›´å°–å³°",
    "ä¸‹è¡Œå°–å³°": "ç«–ç›´å°–å³°",
    "åŒå‘å°–å³°": "ç«–ç›´å°–å³°",
    "ç‚¹å¼‚å¸¸": "ç«–ç›´å°–å³°",
    "é˜¶è·ƒ": "é˜¶è·ƒçªå˜",
    "çªç„¶æ¼‚ç§»": "é˜¶è·ƒçªå˜",
    "ç¼“æ…¢æ¼‚ç§»": "æ¨¡å¼å˜åŒ–",
    "æ¨¡å¼çªå˜": "æ¨¡å¼å˜åŒ–",
    "å¼‚å¸¸å¹³å°": "å¼‚å¸¸å¹³å°"
}

def extract_point_name(annotation_filename):
    """ä»æ ‡æ³¨æ–‡ä»¶åä¸­æå–ç‚¹ä½åç§°
    ä¾‹å¦‚: annotations_æ•°æ®é›†zhlh_100_AC6403B.PV.json -> AC6403B.PV
    å¦‚æœæ— æ³•åŒ¹é…ç‰¹å®šæ¨¡å¼ï¼Œåˆ™è¿”å›å»é™¤æ‰©å±•åçš„æ–‡ä»¶å
    """
    # ç§»é™¤ ".json" åç¼€
    basename = os.path.splitext(annotation_filename)[0]
    
    # å°è¯•åŒ¹é…ç‰¹å®šå‰ç¼€ "annotations_æ•°æ®é›†zhlh_100_"
    match = re.search(r'annotations_æ•°æ®é›†zhlh_100_(.+)$', basename)
    if match:
        return match.group(1)
    
    # å¦‚æœæ²¡æœ‰ç‰¹å®šå‰ç¼€ï¼Œç§»é™¤å¯èƒ½å­˜åœ¨çš„ "annotations_" å‰ç¼€
    if basename.startswith("annotations_"):
        return basename.replace("annotations_", "", 1)
        
    return basename

def extract_point_id(name):
    """Extract point id like ZHLH_XXX.PV from a filename or path."""
    if not name:
        return None
    candidates = []
    for match in re.findall(r'([A-Za-z][A-Za-z0-9_]*\.[A-Za-z0-9]+)', name):
        lower = match.lower()
        if lower.endswith((".csv", ".json", ".jpg", ".png")):
            continue
        if not re.search(r'[A-Za-z]', match):
            continue
        candidates.append(match)
    if not candidates:
        return None
    candidates.sort(key=lambda s: (s.count("_"), len(s)), reverse=True)
    return candidates[0]

def extract_suffix_hint(name):
    """Extract suffix hint like trend_resid for fuzzy match."""
    if not name:
        return None
    for key in ["trend_resid", "resid", "trend"]:
        if key in name:
            return key
    return None

def find_latest_auto_file(output_dir, format_type):
    if not output_dir or not os.path.exists(output_dir):
        return None
    pattern = re.compile(rf"^{re.escape(format_type)}(?:_converted)?_(?:n)?\\d+_\\d{{8}}\\.json$")
    candidates = []
    for fname in os.listdir(output_dir):
        if pattern.match(fname):
            candidates.append(fname)
    if not candidates:
        return None
    candidates.sort(
        key=lambda fn: os.path.getmtime(os.path.join(output_dir, fn)),
        reverse=True
    )
    return os.path.join(output_dir, candidates[0])

def fuzzy_find_file(dir_path, point_id=None, suffix_hint=None, exts=None):
    """Fuzzy find a file by point id and optional suffix hint."""
    if not dir_path or not os.path.exists(dir_path):
        return None
    exts = exts or []
    matches = []
    for fname in os.listdir(dir_path):
        if exts and not any(fname.lower().endswith(ext) for ext in exts):
            continue
        if point_id and point_id not in fname:
            continue
        if suffix_hint and suffix_hint not in fname:
            continue
        matches.append(fname)
    if not matches and point_id:
        for fname in os.listdir(dir_path):
            if exts and not any(fname.lower().endswith(ext) for ext in exts):
                continue
            if point_id and point_id not in fname:
                continue
            matches.append(fname)
    if not matches:
        return None
    def score(fn):
        s = 0
        lower = fn.lower()
        if point_id:
            if fn.startswith(point_id):
                s += 100
            if f"_{point_id}" in fn:
                s += 60
            if point_id in fn:
                s += 30
        if suffix_hint and suffix_hint in fn:
            s += 10
        if lower.startswith("_"):
            s -= 3
        if "qwen" in lower:
            s -= 5
        if "chatts" in lower:
            s -= 5
        s -= len(fn) / 200.0
        return s

    matches.sort(
        key=lambda fn: (score(fn), os.path.getmtime(os.path.join(dir_path, fn))),
        reverse=True
    )
    return os.path.join(dir_path, matches[0])

def plot_csv_to_image(csv_path, output_image_path):
    """Generate a plot from CSV file"""
    try:
        df = pd.read_csv(csv_path)
        # Assuming second column is the value
        value_col = df.columns[1]
        
        plt.figure(figsize=(12, 4))
        plt.plot(df.index, df[value_col], label=value_col, linewidth=1)
        plt.title(f"Time Series: {Path(csv_path).stem}")
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(output_image_path, dpi=100)
        plt.close()
        return True
    except Exception as e:
        print(f"âš ï¸ Plotting failed for {csv_path}: {e}")
        return False

def read_csv_values(csv_path):
    """Read values from CSV file for ChatTS format"""
    try:
        df = pd.read_csv(csv_path)
        # Assuming second column is the value (feature), similar to plot logic
        # If multiple columns, we might need more logic. 
        # For now, take the first non-index column or specific strategy.
        # plot_csv_to_image uses df.columns[1]
        if len(df.columns) > 1:
            value_col = df.columns[1]
            values = df[value_col].tolist()
            # Handle NaN
            values = [0.0 if pd.isna(x) else x for x in values]
            return [values] # Return as shape [1, N] matches [[v1, v2, ...]]
        return []
    except Exception as e:
        print(f"âš ï¸ Reading CSV failed for {csv_path}: {e}")
        return []

def find_csv_file(point_name, image_dir, csv_filename=None, csv_src_dir=None):
    """Find CSV file for a given point in image_dir or csv_src_dir"""
    possible_names = []
    if csv_filename:
        possible_names.append(csv_filename)

    if ".csv" in point_name:
        possible_names.append(point_name)
    else:
        possible_names.append(f"{point_name}.csv")

    # Direct match in image_dir
    for name in possible_names:
        csv_path = os.path.join(image_dir, name)
        if os.path.exists(csv_path):
            return csv_path

    # Direct match in csv_src_dir
    if csv_src_dir:
        for name in possible_names:
            csv_path = os.path.join(csv_src_dir, name)
            if os.path.exists(csv_path):
                return csv_path

    # Try searching by stem
    stem = point_name.replace(".csv", "")
    for f in os.listdir(image_dir):
        if f.endswith(".csv") and stem in f:
            return os.path.join(image_dir, f)

    if csv_src_dir and os.path.exists(csv_src_dir):
        for f in os.listdir(csv_src_dir):
            if f.endswith(".csv") and stem in f:
                return os.path.join(csv_src_dir, f)

    point_id = extract_point_id(csv_filename or point_name)
    suffix_hint = extract_suffix_hint(csv_filename or point_name)
    csv_path = fuzzy_find_file(image_dir, point_id=point_id, suffix_hint=suffix_hint, exts=[".csv"])
    if csv_path:
        return csv_path
    if csv_src_dir:
        csv_path = fuzzy_find_file(csv_src_dir, point_id=point_id, suffix_hint=suffix_hint, exts=[".csv"])
        if csv_path:
            return csv_path

    return None

def find_image_file(point_name, image_dir, csv_filename=None, csv_src_dir=None):
    """æ ¹æ®ç‚¹ä½åç§°æŸ¥æ‰¾å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶
    1. å°è¯•æ ‡å‡†æ ¼å¼: zhlh_100_{point_name}.jpg
    2. å°è¯•ç›´æ¥åŒ¹é…: {point_name}.jpg / .png
    3. å°è¯•ç§»é™¤ .csv åç¼€åŒ¹é…
    4. å¦‚æœæ‰¾ä¸åˆ°å›¾ç‰‡ä½†æœ‰CSV(åœ¨ image_dir æˆ– csv_src_dir)ï¼Œå°è¯•ç”Ÿæˆå›¾ç‰‡
    """
    candidates = [
        f"zhlh_100_{point_name}.jpg",
        f"{point_name}.jpg",
        f"{point_name}.png",
        f"{point_name}"
    ]
    
    if ".csv" in point_name:
        stem = point_name.replace(".csv", "")
        candidates.extend([
            f"{stem}.jpg",
            f"zhlh_100_{stem}.jpg"
        ])

    # Check existing images in image_dir
    for fname in candidates:
        image_path = os.path.join(image_dir, fname)
        if os.path.exists(image_path) and (fname.endswith('.jpg') or fname.endswith('.png')):
            return image_path

    point_id = extract_point_id(csv_filename or point_name)
    image_path = fuzzy_find_file(image_dir, point_id=point_id, suffix_hint=None, exts=[".jpg", ".png"])
    if image_path:
        return image_path
            
    # Try to generate if csv available
    possible_csvs = []
    if csv_filename:
        possible_csvs.append(csv_filename)
        
    if ".csv" in point_name:
         possible_csvs.append(point_name)
    else:
         possible_csvs.append(f"{point_name}.csv")
         
    for csv_name in possible_csvs:
        # 1. Look in image_dir
        csv_path = os.path.join(image_dir, csv_name)
        
        # 2. Look in csv_src_dir if fallback needed
        if not os.path.exists(csv_path) and csv_src_dir and os.path.exists(csv_src_dir):
             fallback_path = os.path.join(csv_src_dir, csv_name)
             if os.path.exists(fallback_path):
                 print(f"â„¹ï¸  Found CSV in source dir: {fallback_path}")
                 csv_path = fallback_path
        
        if os.path.exists(csv_path):
            # Generate image in image_dir (always target the image_dir)
            stem = csv_name.replace(".csv", "")
            target_img_name = f"{stem}.jpg"
            target_img_path = os.path.join(image_dir, target_img_name)
            
            print(f"ğŸ”„ Generating image from CSV: {csv_name} -> {target_img_name}")
            if plot_csv_to_image(csv_path, target_img_path):
                return target_img_path

    if point_id:
        suffix_hint = extract_suffix_hint(csv_filename or point_name)
        csv_path = fuzzy_find_file(image_dir, point_id=point_id, suffix_hint=suffix_hint, exts=[".csv"])
        if not csv_path and csv_src_dir:
            csv_path = fuzzy_find_file(csv_src_dir, point_id=point_id, suffix_hint=suffix_hint, exts=[".csv"])
        if csv_path:
            stem = Path(csv_path).stem
            target_img_name = f"{stem}.jpg"
            target_img_path = os.path.join(image_dir, target_img_name)
            print(f"ğŸ”„ Generating image from CSV: {os.path.basename(csv_path)} -> {target_img_name}")
            if plot_csv_to_image(csv_path, target_img_path):
                return target_img_path
    
    return None

def map_anomaly_type(original_type):
    """å°†åŸå§‹å¼‚å¸¸ç±»å‹æ˜ å°„åˆ°ç›®æ ‡ç±»å‹"""
    return ANOMALY_TYPE_MAPPING.get(original_type, "æ¨¡å¼å˜åŒ–")

def generate_reason(label_text, interval):
    """æ ¹æ®æ ‡ç­¾ç±»å‹å’ŒåŒºé—´ç”ŸæˆåŸå› è¯´æ˜"""
    start, end = interval
    length = end - start + 1
    
    # æ ¹æ®å®é™…çš„æ ‡ç­¾ç±»å‹ç”Ÿæˆæ›´ç²¾ç¡®çš„æè¿°
    if label_text == "ä¸Šè¡Œå°–å³°":
        if start == end:
            return f"ç´¢å¼•ä½ç½®{start}å¤„æ•°æ®å‡ºç°å‘ä¸Šå°–å³°,æ•°å€¼æ€¥å‰§ä¸Šå‡åè¿…é€Ÿå›è½"
        else:
            return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®å‡ºç°å‘ä¸Šå°–å³°,æ•°å€¼æ€¥å‰§ä¸Šå‡åè¿…é€Ÿå›è½"
    
    elif label_text == "ä¸‹è¡Œå°–å³°":
        if start == end:
            return f"ç´¢å¼•ä½ç½®{start}å¤„æ•°æ®å‡ºç°å‘ä¸‹å°–å³°,æ•°å€¼æ€¥å‰§ä¸‹é™åè¿…é€Ÿå›å‡"
        else:
            return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®å‡ºç°å‘ä¸‹å°–å³°,æ•°å€¼æ€¥å‰§ä¸‹é™åè¿…é€Ÿå›å‡"
    
    elif label_text == "åŒå‘å°–å³°":
        if start == end:
            return f"ç´¢å¼•ä½ç½®{start}å¤„æ•°æ®å‡ºç°åŒå‘å°–å³°,æ•°å€¼å…ˆæ€¥å‰§å˜åŒ–ååå‘å˜åŒ–"
        else:
            return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®å‡ºç°åŒå‘å°–å³°,æ•°å€¼å‘ˆç°å‰§çƒˆéœ‡è¡"
    
    elif label_text == "é˜¶è·ƒä¸Šå‡":
        return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®å‘ç”Ÿé˜¶è·ƒä¸Šå‡,æ•°å€¼å¿«é€Ÿè·ƒè¿åˆ°æ›´é«˜æ°´å¹³"
    
    elif label_text == "é˜¶è·ƒä¸‹é™":
        return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®å‘ç”Ÿé˜¶è·ƒä¸‹é™,æ•°å€¼å¿«é€Ÿè·ƒè¿åˆ°æ›´ä½æ°´å¹³"
    
    elif label_text == "çªç„¶æ¼‚ç§»":
        return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®å‘ç”Ÿçªç„¶æ¼‚ç§»,åŸºçº¿æ°´å¹³å‘ç”Ÿçªå˜"
    
    elif label_text == "ç¼“æ…¢æ¼‚ç§»":
        return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®å‘ç”Ÿç¼“æ…¢æ¼‚ç§»,åŸºçº¿æ°´å¹³é€æ¸åç§»"
    
    elif label_text == "ç‚¹å¼‚å¸¸":
        if start == end:
            return f"ç´¢å¼•ä½ç½®{start}å¤„å­˜åœ¨å­¤ç«‹å¼‚å¸¸ç‚¹,ä¸å‘¨å›´æ•°æ®æ˜æ˜¾ä¸ç¬¦"
        else:
            return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…å­˜åœ¨å¤šä¸ªå­¤ç«‹å¼‚å¸¸ç‚¹"
    
    elif label_text == "åŒºé—´å¼‚å¸¸":
        return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®æ•´ä½“å¼‚å¸¸,ä¸æ­£å¸¸æ¨¡å¼å­˜åœ¨æ˜¾è‘—å·®å¼‚"
    
    elif label_text == "éœ‡è¡åŒºé—´":
        return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®å‘ˆç°å¼‚å¸¸éœ‡è¡,æ³¢åŠ¨å¹…åº¦æ˜æ˜¾å¢å¤§"
    
    elif label_text == "ä¸Šä¸‹æ–‡å¼‚å¸¸":
        return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®ä¸å‰åä¸Šä¸‹æ–‡ä¸ä¸€è‡´,å­˜åœ¨æ¨¡å¼çªå˜"
    
    # å…œåº•æè¿°ï¼ˆä¸åº”è¯¥åˆ°è¿™é‡Œï¼‰
    else:
        if start == end:
            return f"ç´¢å¼•ä½ç½®{start}å¤„æ•°æ®å­˜åœ¨å¼‚å¸¸"
        else:
            return f"ç´¢å¼•åŒºé—´[{start},{end}]å†…æ•°æ®å­˜åœ¨å¼‚å¸¸"

def convert_overall_attribute_to_chinese(overall_attr):
    """å°†overall_attributeè½¬æ¢ä¸ºä¸­æ–‡æè¿°"""
    # å®šä¹‰æ˜ å°„å…³ç³»
    mappings = {
        "frequency": {
            "high_freq": "é«˜é¢‘",
            "low_freq": "ä½é¢‘"
        },
        "noise": {
            "noisy": "é«˜å™ªå£°",
            "clean": "ä¸­ç­‰å™ªå£°",
            "almost_no_noise": "ä½å™ªå£°",
            "label_1766469170459": "æ— å™ªå£°"
        },
        "seasonal": {
            "has_periodic": "æœ‰å‘¨æœŸæ€§",
            "no_periodic": "æ— å‘¨æœŸæ€§",
            "label_1766475567943": "å±€éƒ¨æœ‰å‘¨æœŸæ€§"
        },
        "trend": {
            "increase": "ä¸Šå‡è¶‹åŠ¿",
            "decrease": "ä¸‹é™è¶‹åŠ¿",
            "stable": "è¶‹åŠ¿ç¨³å®š",
            "multiple": "å¤šæ®µå¼è¶‹åŠ¿",
            "label_1766469189296": "æ— æ˜æ˜¾è¶‹åŠ¿"
        }
    }
    
    descriptions = []
    for key, value in overall_attr.items():
        if value and key in mappings and value in mappings[key]:
            descriptions.append(mappings[key][value])
    
    return "ã€".join(descriptions) if descriptions else ""

def convert_annotation_to_conversation(annotation_data, image_path):
    """å°†æ ‡æ³¨æ•°æ®è½¬æ¢ä¸ºå¯¹è¯æ ¼å¼"""
    
    # ç”Ÿæˆç”¨æˆ·æç¤ºè¯ - ä½¿ç”¨å®é™…çš„æ ‡ç­¾ç±»å‹
    user_prompt = """<image>
ä½ æ˜¯ä¸€ä½æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹ä¸“å®¶ã€‚è¯·åˆ†æå›¾ä¸­çš„æ—¶é—´åºåˆ—æ•°æ®,è¯†åˆ«å¼‚å¸¸åŒºé—´ã€‚

å¼‚å¸¸ç±»å‹ï¼š
1. å°–å³°ç±»ï¼šä¸Šè¡Œå°–å³°ã€ä¸‹è¡Œå°–å³°ã€åŒå‘å°–å³°
2. é˜¶è·ƒç±»ï¼šé˜¶è·ƒä¸Šå‡ã€é˜¶è·ƒä¸‹é™
3. æ¼‚ç§»ç±»ï¼šçªç„¶æ¼‚ç§»ã€ç¼“æ…¢æ¼‚ç§»
4. ç‰¹æ®Šå¼‚å¸¸æ®µï¼šç‚¹å¼‚å¸¸ã€åŒºé—´å¼‚å¸¸ã€éœ‡è¡åŒºé—´ã€ä¸Šä¸‹æ–‡å¼‚å¸¸

è¯·åŸºäºå…¨å±€ä¿¡å·ç‰¹å¾è¯†åˆ«å¼‚å¸¸ã€‚è¾“å‡ºå¿…é¡»æ˜¯æ ‡å‡†JSONæ ¼å¼ï¼š

{"status":"success","detected_anomalies":[{"interval":[start,end],"type":"ç±»å‹","reason":"åŸå› "}]}

è‹¥æ— å¼‚å¸¸ï¼š
{"status":"success","detected_anomalies":[]}

è¯·ç²¾ç¡®æ ‡æ³¨å¼‚å¸¸åŒºé—´çš„èµ·æ­¢ç´¢å¼•ã€‚"""
    
    # ç”ŸæˆåŠ©æ‰‹å“åº”ï¼ˆåŒ…å«æ‰€æœ‰å¼‚å¸¸æ£€æµ‹ç»“æœå’Œoverall_attributeï¼‰
    detected_anomalies = []
    
    # å¤„ç†æ¯ä¸ªæ ‡æ³¨
    for annotation in annotation_data.get("annotations", []):
        label_text = annotation["label"]["text"]
        # ç›´æ¥ä½¿ç”¨åŸå§‹æ ‡ç­¾æ–‡æœ¬ä½œä¸ºtypeï¼Œä¸å†æ˜ å°„
        anomaly_type = label_text
        
        # å¤„ç†æ¯ä¸ªsegment
        for segment in annotation.get("segments", []):
            start = segment["start"]
            end = segment["end"]
            reason = generate_reason(label_text, [start, end])
            
            anomaly = {
                "interval": [start, end],
                "type": anomaly_type,
                "reason": reason
            }
            detected_anomalies.append(anomaly)
    
    # ç‰¹æ®Šå¤„ç†ï¼šæ— å¼‚å¸¸çš„æƒ…å†µï¼ˆæ²¡æœ‰annotationsæˆ–annotationsä¸ºç©ºï¼‰
    if not detected_anomalies:
        # æ— å¼‚å¸¸æ—¶ï¼Œè¾“å‡ºæ ¼å¼ï¼š{"status":"success","detected_anomalies":[{"type":"æ— å¼‚å¸¸","reason":"è¯¥æ•°æ®ä¸åšå¼‚å¸¸æ£€æµ‹"}]}
        no_anomaly_result = {
            "status": "success",
            "detected_anomalies": [
                {
                    "type": "æ— å¼‚å¸¸",
                    "reason": "è¯¥æ•°æ®ä¸åšå¼‚å¸¸æ£€æµ‹"
                }
            ]
        }
        assistant_value = json.dumps(no_anomaly_result, ensure_ascii=False)
        
        # å¦‚æœæœ‰overall_attributeï¼Œæ·»åŠ å…¨å±€å±æ€§
        if "overall_attribute" in annotation_data:
            overall_attr = annotation_data["overall_attribute"]
            filtered_attr = {k: v for k, v in overall_attr.items() if v}
            if filtered_attr:
                chinese_desc = convert_overall_attribute_to_chinese(filtered_attr)
                if chinese_desc:
                    overall_result = {
                        "status": "success",
                        "detected_anomalies": [
                            {
                                "type": "å…¨å±€å±æ€§",
                                "reason": chinese_desc
                            }
                        ]
                    }
                    assistant_value = assistant_value + "," + json.dumps(overall_result, ensure_ascii=False)
    else:
        # æœ‰å¼‚å¸¸çš„æƒ…å†µï¼šä¸ºæ¯ä¸ªå¼‚å¸¸åˆ›å»ºå•ç‹¬çš„JSONå¯¹è±¡ï¼Œç„¶åç”¨é€—å·è¿æ¥
        individual_results = []
        for anomaly in detected_anomalies:
            result = {
                "status": "success",
                "detected_anomalies": [anomaly]
            }
            individual_results.append(json.dumps(result, ensure_ascii=False))
        
        assistant_value = ",".join(individual_results)
        
        # æ·»åŠ overall_attributeåˆ°æœ€åï¼ˆè½¬æ¢ä¸ºä¸­æ–‡æ ¼å¼ï¼‰
        if "overall_attribute" in annotation_data:
            overall_attr = annotation_data["overall_attribute"]
            filtered_attr = {k: v for k, v in overall_attr.items() if v}
            if filtered_attr:
                chinese_desc = convert_overall_attribute_to_chinese(filtered_attr)
                if chinese_desc:
                    overall_result = {
                        "status": "success",
                        "detected_anomalies": [
                            {
                                "type": "å…¨å±€å±æ€§",
                                "reason": chinese_desc
                            }
                        ]
                    }
                    assistant_value = assistant_value + "," + json.dumps(overall_result, ensure_ascii=False)
    
    # æ„å»ºå¯¹è¯æ ¼å¼
    conversation = {
        "image": image_path,
        "conversations": [
            {
                "from": "user",
                "value": user_prompt
            },
            {
                "from": "assistant",
                "value": assistant_value
            }
        ]
    }
    
    return conversation

def convert_to_chatts_format(conversation, csv_path, identifier=None):
    """Convert ShareGPT format to ChatTS format (Alpaca-like with timeseries content)"""
    # content from csv
    target_values = []
    if csv_path:
        target_values = read_csv_values(csv_path)
    
    conversations = conversation.get("conversations", [])
    
    user_text = ""
    assistant_text = ""
    
    for conv in conversations:
        if conv["from"] == "user":
            user_text = conv["value"]
        elif conv["from"] == "assistant":
            assistant_text = conv["value"]
            
    return {
        "target": target_values, # List of lists
        "input": user_text,
        "output": assistant_text,
        "start": ["2023-01-01 00:00:00"], # Dummy start time if not available, matching reference
        "id": identifier or "unknown"
    }

def convert_annotations(input_dir, output_file, image_dir, filename=None, format_type="qwen", csv_src_dir=None):
    """
    è½¬æ¢æ ‡æ³¨æ–‡ä»¶ï¼Œæ”¯æŒå•ä¸ªæ–‡ä»¶æˆ–æ‰¹é‡è½¬æ¢ã€‚
    :param input_dir: åŒ…å«æ ‡æ³¨JSONæ–‡ä»¶çš„è¾“å…¥ç›®å½•ã€‚
    :param output_file: è¾“å‡ºJSONæ–‡ä»¶çš„è·¯å¾„ã€‚
    :param image_dir: åŒ…å«å¯¹åº”å›¾ç‰‡æ–‡ä»¶çš„ç›®å½•ã€‚
    :param filename: å¦‚æœæŒ‡å®šï¼Œåˆ™åªè½¬æ¢æ­¤å•ä¸ªæ–‡ä»¶ï¼›å¦åˆ™æ‰¹é‡è½¬æ¢input_dirä¸­çš„æ‰€æœ‰æ–‡ä»¶ã€‚
    :param format_type: è¾“å‡ºæ ¼å¼ ("qwen" æˆ– "chatts")ã€‚
    :param csv_src_dir: æŸ¥æ‰¾CSVæ–‡ä»¶çš„å¤‡ç”¨ç›®å½•ã€‚
    """
    
    all_conversations = []
    success_count = 0
    failed_files = []

    if filename: # Single file conversion
        annotation_path = os.path.join(input_dir, filename)
        if not os.path.exists(annotation_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {annotation_path}")
            return None

        print(f"[{1}/{1}] å¤„ç†: {filename}", end=" ... ")
        try:
            with open(annotation_path, 'r', encoding='utf-8') as f:
                annotation_data = json.load(f)
            
            point_name = extract_point_name(filename)
            csv_filename = annotation_data.get("filename")

            csv_path = find_csv_file(point_name, image_dir, csv_filename, csv_src_dir)
            image_path = find_image_file(point_name, image_dir, csv_filename, csv_src_dir)

            if not image_path and csv_filename:
                image_path = find_image_file(csv_filename, image_dir, csv_filename, csv_src_dir)
                if not point_name:
                    point_name = csv_filename

            if format_type == "qwen" and not image_path:
                print("âŒ æ‰¾ä¸åˆ°å¯¹åº”å›¾ç‰‡/CSV")
                msg = f"ç¼ºå¤±æºæ–‡ä»¶ (ç‚¹ä½: {point_name})ã€‚è¯·æ£€æŸ¥ {image_dir} æˆ– {csv_src_dir}ã€‚å¦‚å·²ä¸¢å¤±ï¼Œè¯·å‰å¾€[æ•°æ®è·å–]æ¨¡å—é‡æ–°é‡‡é›†ã€‚"
                failed_files.append((filename, msg))
                return all_conversations
            if format_type == "chatts" and not csv_path:
                 print("âš ï¸ æ‰¾ä¸åˆ°å¯¹åº”CSV (å°†ä½¿ç”¨ç©ºæ•°æ®)")
                 print(f"  å»ºè®®å‰å¾€[æ•°æ®è·å–]æ¨¡å—é‡æ–°é‡‡é›†ç‚¹ä½: {point_name}")
            
            conversation = convert_annotation_to_conversation(annotation_data, image_path or "")
            
            if format_type == "chatts":
                final_data = convert_to_chatts_format(conversation, csv_path, point_name or filename)
            else:
                final_data = conversation
            
            all_conversations.append(final_data)
            success_count += 1
            print("âœ…")

        except Exception as e:
            print(f"âŒ é”™è¯¯: {str(e)}")
            failed_files.append((filename, str(e)))

    else: # Batch conversion
        json_files = [f for f in os.listdir(input_dir) if f.endswith('.json')]
        total_files = len(json_files)
        
        print(f"ğŸ”„ å¼€å§‹æ‰¹é‡è½¬æ¢ï¼Œå…± {total_files} ä¸ªæ–‡ä»¶...")
        print("=" * 80)
        
        for idx, current_filename in enumerate(json_files, 1):
            annotation_path = os.path.join(input_dir, current_filename)
            
            print(f"[{idx}/{total_files}] å¤„ç†: {current_filename}", end=" ... ")
            
            try:
                with open(annotation_path, 'r', encoding='utf-8') as f:
                    annotation_data = json.load(f)
                
                point_name = extract_point_name(current_filename)
                csv_filename = annotation_data.get("filename")
                
                csv_path = find_csv_file(point_name, image_dir, csv_filename, csv_src_dir)
                image_path = find_image_file(point_name, image_dir, csv_filename, csv_src_dir)
                
                if not image_path:
                    if csv_filename:
                        image_path = find_image_file(csv_filename, image_dir, csv_filename, csv_src_dir)
                
                if format_type == "qwen" and not image_path:
                    print("âŒ æ‰¾ä¸åˆ°å¯¹åº”å›¾ç‰‡/CSV")
                    msg = f"ç¼ºå¤±æºæ–‡ä»¶ (ç‚¹ä½: {point_name})ã€‚è¯·æ£€æŸ¥ {image_dir} æˆ– {csv_src_dir}ã€‚å¦‚å·²ä¸¢å¤±ï¼Œè¯·å‰å¾€[æ•°æ®è·å–]æ¨¡å—é‡æ–°é‡‡é›†ã€‚"
                    failed_files.append((current_filename, msg))
                    continue
                if format_type == "chatts" and not csv_path:
                    print("âš ï¸ æ‰¾ä¸åˆ°å¯¹åº”CSV (å°†ä½¿ç”¨ç©ºæ•°æ®)")
                    print(f"  å»ºè®®å‰å¾€[æ•°æ®è·å–]æ¨¡å—é‡æ–°é‡‡é›†ç‚¹ä½: {point_name}")

                conversation = convert_annotation_to_conversation(annotation_data, image_path or "")
                
                if format_type == "chatts":
                    final_data = convert_to_chatts_format(conversation, csv_path, point_name or current_filename)
                else:
                    final_data = conversation
                    
                all_conversations.append(final_data)
                
                success_count += 1
                print("âœ…")
                
            except Exception as e:
                print(f"âŒ é”™è¯¯: {str(e)}")
                failed_files.append((current_filename, str(e)))
    
    print("\n" + "=" * 80)
    print(f"ğŸ“Š è½¬æ¢ç»Ÿè®¡ï¼šæˆåŠŸ {success_count}/{len(json_files) if not filename else 1}")
    
    if failed_files:
        print(f"\nâš ï¸  å¤±è´¥çš„æ–‡ä»¶ ({len(failed_files)}):")
        for fname, reason in failed_files:
            print(f"  - {fname}: {reason}")
    
    # Auto-name output file if using default placeholder name
    final_output_file = output_file
    output_dir = output_file if os.path.isdir(output_file) else os.path.dirname(output_file)
    output_basename = os.path.basename(output_file)
    if output_basename == "converted_data.json" or os.path.isdir(output_file):
        date_tag = datetime.now().strftime("%Y%m%d")
        final_output_file = os.path.join(
            output_dir,
            f"{format_type}_converted_{len(all_conversations)}_{date_tag}.json"
        )

    os.makedirs(os.path.dirname(final_output_file), exist_ok=True)
    with open(final_output_file, 'w', encoding='utf-8') as f:
        json.dump(all_conversations, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ¨ æ‰€æœ‰è½¬æ¢ç»“æœå·²ä¿å­˜åˆ°: {final_output_file}")
    print(f"ğŸ“¦ å…± {len(all_conversations)} æ¡å¯¹è¯æ•°æ®")
    
    return all_conversations

def convert_single_file(annotation_path, image_dir, output_dir=None, format_type="qwen"):
    """è½¬æ¢å•ä¸ªæ ‡æ³¨æ–‡ä»¶"""
    # This function is now deprecated/refactored into convert_annotations
    # Keeping it for backward compatibility if needed, but its logic is moved.
    raise NotImplementedError("convert_single_file has been refactored. Use convert_annotations directly.")

def batch_convert_all_files(annotation_dir, image_dir, output_file, format_type="qwen"):
    """æ‰¹é‡è½¬æ¢æ‰€æœ‰æ ‡æ³¨æ–‡ä»¶å¹¶ä¿å­˜åˆ°ä¸€ä¸ªJSONæ–‡ä»¶ä¸­"""
    # This function is now deprecated/refactored into convert_annotations
    # Keeping it for backward compatibility if needed, but its logic is moved.
    raise NotImplementedError("batch_convert_all_files has been refactored. Use convert_annotations directly.")

import argparse
import sys
import os
import json # Ensure json is imported

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Convert annotation JSON files to ChatTS conversation format")
    parser.add_argument("--input-dir", required=True, help="Input directory containing annotation JSON files")
    parser.add_argument("--image-dir", required=True, help="Directory containing corresponding images")
    parser.add_argument("--output", required=True, help="Output JSON file path")
    parser.add_argument("--file", help="Specific filename to convert (optional)")
    parser.add_argument("--format", default="qwen", choices=["qwen", "chatts"], help="Output format (default: qwen)")
    parser.add_argument("--csv-src", help="Fallback directory to look for CSVs if images missing (optional)")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.input_dir):
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {args.input_dir}")
        sys.exit(1)
        
    if not os.path.exists(args.image_dir):
        print(f"âŒ å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {args.image_dir}")
        # sys.exit(1) # Allow proceeding if image_dir is missing, but conversion might fail for Qwen format
        # If image_dir is missing, we should still allow chatts format if csv_src is provided.
        # Or, if qwen, it will fail later.
        pass # Let convert_annotations handle the specific image/csv missing errors
        
    if args.file:
        # å•æ–‡ä»¶è½¬æ¢æ¨¡å¼
        print(f"ğŸ”„ æ­£åœ¨è½¬æ¢å•ä¸ªæ–‡ä»¶: {args.file}")
        annotation_path = os.path.join(args.input_dir, args.file)
        if not os.path.exists(annotation_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {annotation_path}")
            sys.exit(1)
            
        placeholder_output = os.path.isdir(args.output) or os.path.basename(args.output) == "converted_data.json"
        output_dir = args.output if os.path.isdir(args.output) else os.path.dirname(args.output)
        base_output_path = None

        if placeholder_output:
            base_output_path = find_latest_auto_file(output_dir, args.format)
        else:
            base_output_path = args.output

        # å…ˆè¯»å–å·²æœ‰è¾“å‡ºï¼Œé¿å…è¢«è½¬æ¢è¿‡ç¨‹è¦†ç›–
        all_conversations = []
        if base_output_path and os.path.exists(base_output_path):
            try:
                with open(base_output_path, 'r', encoding='utf-8') as f:
                    all_conversations = json.load(f)
            except:
                pass

        # è½¬æ¢å•ä¸ªæ–‡ä»¶ï¼ˆä½¿ç”¨ä¸´æ—¶è¾“å‡ºé¿å…è¦†ç›–ç›®æ ‡æ–‡ä»¶ï¼‰
        with tempfile.NamedTemporaryFile(suffix=".json", delete=False) as tmp:
            tmp_path = tmp.name
        result = convert_annotations(
            args.input_dir,
            tmp_path,
            args.image_dir,
            filename=args.file,
            format_type=args.format,
            csv_src_dir=args.csv_src,
        )
        try:
            os.unlink(tmp_path)
        except:
            pass
        conversation = result[0] if result else None

        if conversation:
            
            # Remove old entry for this image/file if exists
            # Determine key based on format
            if args.format == "chatts":
                # For ChatTS, we check "input" or "target" equality? Or maybe we can't easily dedup without ID?
                # The previous logic relied on image path.
                # We'll skip dedup for ChatTS or use input text as partial key.
                pass
            else:
                new_image_path = conversation.get("image")
                new_point_id = extract_point_id(new_image_path or args.file)
                if new_image_path or new_point_id:
                    def should_keep(c):
                        img = c.get("image", "")
                        if new_image_path and img == new_image_path:
                            return False
                        if new_point_id and extract_point_id(img) == new_point_id:
                            return False
                        return True
                    all_conversations = [c for c in all_conversations if should_keep(c)]
            
            all_conversations.append(conversation)

            # ä»…å†™è‡ªåŠ¨å‘½åæ–‡ä»¶ï¼ˆæˆ–ç”¨æˆ·æŒ‡å®šæ–‡ä»¶ï¼‰
            if placeholder_output:
                date_tag = datetime.now().strftime("%Y%m%d")
                final_output_path = os.path.join(
                    output_dir,
                    f"{args.format}_converted_{len(all_conversations)}_{date_tag}.json"
                )
            else:
                final_output_path = args.output

            with open(final_output_path, 'w', encoding='utf-8') as f:
                json.dump(all_conversations, f, ensure_ascii=False, indent=2)
            print(f"âœ… å•æ–‡ä»¶å·²æ›´æ–°è‡³: {final_output_path}")
        else:
            print("âŒ å•æ–‡ä»¶è½¬æ¢å¤±è´¥ (å¯èƒ½æ˜¯æ‰¾ä¸åˆ°å›¾ç‰‡æˆ–CSV)")
            sys.exit(1)
            
    else:
        # æ‰¹é‡è½¬æ¢æ‰€æœ‰æ–‡ä»¶
        convert_annotations(
            args.input_dir,
            args.output,
            args.image_dir,
            format_type=args.format,
            csv_src_dir=args.csv_src,
        )

if __name__ == "__main__":
    main()
